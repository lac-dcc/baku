model,acronym,size,compiled,total,proportion,regressions,time
llama3.1,LL3,8,131,186,0.7043010752688172,7,56.575453758239746
codellama7,CL7,7,12,12,1.0,0,4.355954170227051
codellama13,CL13,13,7,11,0.6363636363636364,0,2.866863250732422
deepseekr1,DSR1,8,19,27,0.7037037037037037,0,9.530495166778564
deepseekv1instructed,DSC1,2,19,46,0.41304347826086957,0,12.664323806762695
deepseekv2instructed,DSC2,16,110,126,0.873015873015873,0,51.40255808830261
