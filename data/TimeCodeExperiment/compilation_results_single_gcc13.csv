model,acronym,size,compiled,total,proportion,regressions,time
llama3.1,LL3.1,8,83,89,0.9325842696629213,0,37.21995496749878
codellama7,CL7,7,20,20,1.0,0,8.986107349395752
codellama13,CL13,13,70,81,0.8641975308641975,0,30.158594846725464
deepseekr1,DSR1,8,75,98,0.7653061224489796,3,34.416351318359375
deepseekv1instructed,DSC1,2,36,65,0.5538461538461539,0,19.838229417800903
deepseekv2instructed,DSC2,16,151,157,0.9617834394904459,1,66.92397093772888
